A collection of ETL (Extract, Transform, Load) pipelines and utilities for healthcare data management and analytics, developed using Azure Databricks and Azure Storage Containers.

This project was inspired by the course _"Master Azure Databricks with PySpark: Your Hands-On Guide to Advanced Data Engineering and Analysis."_ It showcases practical implementations using PySpark, Delta Lake, Databricks Workflows, and Azure Data Lake Storage to solve common data engineering challenges in the healthcare domain.

**Technologies used:**  
- Azure Databricks  
- Apache Spark (PySpark)  
- Delta Lake  
- Azure Data Lake Storage / Azure Blob Storage  
- Databricks Workflows  
- Python  
- SQL  
- Git & GitHub  

**Skills demonstrated:**  
- Cloud data engineering on Azure  
- Distributed data processing with PySpark  
- Data ingestion, transformation, and loading (ETL)  
- Data quality and validation  
- Workflow orchestration and automation  
- Performance optimization and scalability  
- Secure handling of healthcare data  
